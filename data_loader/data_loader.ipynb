{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from patchify import patchify\n",
    "\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nibabel.processing import resample_to_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, images_ct_scans, images_ct_masks, transform=None):\n",
    "        self.images_ct_scans = images_ct_scans\n",
    "        self.images_ct_masks = images_ct_masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_ct_scans)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = str(self.images_ct_scans[idx])\n",
    "        print(\"image_file\", image_file)\n",
    "        image = cv2.imread(image_file)\n",
    "        print(\"image\", image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # path_elements = list(Path(image_file).parts)\n",
    "        # index = path_elements.index('images')\n",
    "        # path_elements[index] = 'labels'\n",
    "\n",
    "        mask_filepath = self.images_ct_masks[idx]\n",
    "        mask = cv2.imread(str(mask_filepath))\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # if self.transform is not None:\n",
    "        #     image = self.transform(image=image)[\"image\"]\n",
    "            # mask = self.transform(image=mask)[\"image\"]\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "        A.Resize(height=50, width=50),\n",
    "        # A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        # A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.ToFloat(max_value=255, always_apply=True),\n",
    "        ToTensorV2()\n",
    "        ])\n",
    "        self.transforms = A.Compose([\n",
    "        A.Resize(height=50, width=50),\n",
    "        # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.ToFloat(max_value=255, always_apply=True),\n",
    "        ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "        self.ct_dataset= None\n",
    "\n",
    "        self.all_ct_scan_patches = []\n",
    "        self.all_ct_mask_patches = []\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.ct_dataset = load_dataset(\"andreped/AeroPath\")\n",
    "\n",
    "        print('len dataset', self.ct_dataset['test'].num_rows)\n",
    "\n",
    "\n",
    "        print(self.ct_dataset)\n",
    "        for img in range(len(self.ct_dataset['test'])):\n",
    "            # print(img)     #just stop here to see all file names printed\n",
    "                    \n",
    "            large_image = self.ct_dataset['test'][img]\n",
    "\n",
    "            ct_image = nib.load(large_image[\"ct\"])\n",
    "            ct_image = resample_to_output(ct_image, order=1)\n",
    "            ct_data_scan = ct_image.get_fdata().astype(\"int32\")\n",
    "            # print(ct_data_scan.shape)\n",
    "\n",
    "            ct_mask = nib.load(large_image[\"airways\"])\n",
    "            ct_mask = resample_to_output(ct_mask, order=1)\n",
    "            ct_data_mask = ct_mask.get_fdata().astype(\"int32\")\n",
    "                    \n",
    "            percent_size_x = 0.5  # Przykładowo 20% w osi X\n",
    "            percent_size_y = 0.5  # Przykładowo 20% w osi Y\n",
    "            fixed_size_z = 50  # Stała liczba sliców w osi Z\n",
    "\n",
    "            scan_shape = ct_data_scan.shape\n",
    "\n",
    "            patch_size_x = min(int(round(scan_shape[0] * percent_size_x)), scan_shape[0])\n",
    "            patch_size_y = min(int(round(scan_shape[1] * percent_size_y)), scan_shape[1])\n",
    "\n",
    "            patch_size = (patch_size_x, patch_size_y, fixed_size_z)\n",
    "\n",
    "            print(patch_size)\n",
    "\n",
    "            step = patch_size\n",
    "\n",
    "            patches_scan = patchify(ct_data_scan, patch_size, step=step)\n",
    "            patches_mask = patchify(ct_data_mask, patch_size, step=step)\n",
    "\n",
    "            # Pętle do iteracji przez otrzymane fragmenty danego skanu\n",
    "            for i in range(patches_scan.shape[0]):\n",
    "                for j in range(patches_scan.shape[1]):\n",
    "                    for k in range(patches_scan.shape[2]):\n",
    "                        patch_scan = patches_scan[i, j, k, :, :, :]\n",
    "                        patch_mask = patches_mask[i, j, k, :, :, :]\n",
    "                            \n",
    "                        self.all_ct_scan_patches.append(patch_scan)\n",
    "                        self.all_ct_mask_patches.append(patch_mask)\n",
    "\n",
    "##################################################################### for testing purposes\n",
    "            # print(len(all_img_patches))\n",
    "            # fig, ax = plt.subplots(2, 2, figsize=(20, 12))\n",
    "            # ax[0,0].cla()\n",
    "            # ax[0,1].cla()\n",
    "            # ax[1,0].cla()\n",
    "            # ax[1,1].cla()\n",
    "            # ax[0,0].imshow(all_img_patches[0][..., 1], cmap=\"gray\")\n",
    "            # ax[0,1].imshow(all_img_patches[patches.shape[2] + 1][..., 1], cmap=\"gray\")\n",
    "            # ax[1,0].imshow(all_img_patches[2*patches.shape[2] + 1][..., 1], cmap=\"gray\")\n",
    "            # ax[1,1].imshow(all_img_patches[3*patches.shape[2] + 1][..., 1], cmap=\"gray\")\n",
    "\n",
    "            # plt.show()\n",
    "\n",
    "            # break\n",
    "#####################################################################\n",
    "\n",
    "        # images = np.array(all_img_patches)\n",
    "        # images = np.expand_dims(images, -1)\n",
    "                        \n",
    "            if img == 1:\n",
    "                break\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        # Split the data and assign datasets for use in dataloaders\n",
    "\n",
    "        all_indices = np.arange(self.ct_dataset['test'].num_rows)\n",
    "\n",
    "        # self.all_ct_scan_patches = np.array([np.array(patch) for patch in self.all_ct_scan_patches])\n",
    "        # self.all_ct_mask_patches = np.array([np.array(patch) for patch in self.all_ct_mask_patches])\n",
    "\n",
    "        self.all_ct_scan_patches = np.array(self.all_ct_scan_patches, dtype=object)\n",
    "        self.all_ct_mask_patches = np.array(self.all_ct_mask_patches, dtype=object)\n",
    "\n",
    "        train_index, val_index = train_test_split(all_indices, test_size = 0.3, random_state=42)\n",
    "        val_index, test_index = train_test_split(val_index, test_size = 0.5, random_state=42)\n",
    "\n",
    "        # print('Typ 1:', self.all_ct_scan_patches)\n",
    "        # print('Typ 2:', type(self.all_ct_mask_patches))\n",
    "        print('Indeksy zbioru walidacyjnego:', val_index)\n",
    "        print('Indeksy zbioru testowego:', test_index)\n",
    "        print('Indeksy zbioru treningowego:', train_index)\n",
    "\n",
    "        train_scans = self.all_ct_scan_patches[train_index]\n",
    "        train_masks = self.all_ct_mask_patches[train_index]\n",
    "\n",
    "        val_scans = self.all_ct_scan_patches[val_index]\n",
    "        val_masks = self.all_ct_mask_patches[val_index]\n",
    "\n",
    "        test_scans = self.all_ct_scan_patches[test_index]\n",
    "        test_masks = self.all_ct_mask_patches[test_index]\n",
    "\n",
    "\n",
    "        self.train_dataset = CTDataset(train_scans, train_masks, transform=self.augmentations)\n",
    "        self.val_dataset = CTDataset(val_scans, val_masks, transform=self.transforms)\n",
    "        self.test_dataset = CTDataset(test_scans, test_masks, transform=self.transforms)\n",
    "\n",
    "        data = self.train_dataset.__getitem__(0)\n",
    "        print(data)\n",
    "\n",
    "        print(self.train_dataset)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=12)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=12)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len dataset 27\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['ct', 'airways', 'lungs'],\n",
      "        num_rows: 27\n",
      "    })\n",
      "})\n",
      "(194, 194, 50)\n",
      "(190, 190, 50)\n",
      "Indeksy zbioru walidacyjnego: [ 9  0 21 16]\n",
      "Indeksy zbioru testowego: [17 13 11  8 12]\n",
      "Indeksy zbioru treningowego: [24  1  4  5  2 15 22  3 25 23 18 26 20  7 10 14 19  6]\n",
      "image_file [[[  398   383   310 ...   321   309   317]\n",
      "  [  272   375   393 ...   309   297   288]\n",
      "  [  181   299   350 ...   242   236   279]\n",
      "  ...\n",
      "  [-1005 -1004 -1007 ...  -993 -1011 -1003]\n",
      "  [-1007 -1010 -1008 ...  -998 -1001 -1009]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[  491   452   375 ...   314   313   328]\n",
      "  [  467   486   483 ...   309   276   278]\n",
      "  [  382   418   368 ...   245   267   247]\n",
      "  ...\n",
      "  [ -997  -999 -1007 ...  -996  -997  -989]\n",
      "  [-1009 -1011 -1013 ...  -996 -1001  -995]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[  442   460   384 ...   291   280   299]\n",
      "  [  426   462   418 ...   267   241   258]\n",
      "  [  394   451   379 ...   288   262   246]\n",
      "  ...\n",
      "  [ -985  -992 -1002 ... -1006  -992  -998]\n",
      "  [ -996 -1006 -1000 ... -1008  -997  -994]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1004 -1009 -1004 ...  -994 -1001  -990]\n",
      "  [-1015  -996 -1004 ... -1003 -1004 -1013]\n",
      "  [-1012  -998  -996 ... -1004 -1007 -1011]\n",
      "  ...\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[ -988  -999  -990 ...  -995 -1005  -991]\n",
      "  [ -996 -1002  -994 ...  -995 -1006  -998]\n",
      "  [-1004  -999 -1000 ...  -999 -1015 -1012]\n",
      "  ...\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]]]\n",
      "image None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1710.625] global loadsave.cpp:248 findDecoder imread_('[[[  398   383   310 ...   321   309   317]\n",
      "  [  272   375   393 ...   309   297   288]\n",
      "  [  181   299   350 ...   242   236   279]\n",
      "  ...\n",
      "  [-1005 -1004 -1007 ...  -993 -1011 -1003]\n",
      "  [-1007 -1010 -1008 ...  -998 -1001 -1009]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[  491   452   375 ...   314   313   328]\n",
      "  [  467   486   483 ...   309   276   278]\n",
      "  [  382   418   368 ...   245   267   247]\n",
      "  ...\n",
      "  [ -997  -999 -1007 ...  -996  -997  -989]\n",
      "  [-1009 -1011 -1013 ...  -996 -1001  -995]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[  442   460   384 ...   291   280   299]\n",
      "  [  426   462   418 ...   267   241   258]\n",
      "  [  394   451   379 ...   288   262   246]\n",
      "  ...\n",
      "  [ -985  -992 -1002 ... -1006  -992  -998]\n",
      "  [ -996 -1006 -1000 ... -1008  -997  -994]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1004 -1009 -1004 ...  -994 -1001  -990]\n",
      "  [-1015  -996 -1004 ... -1003 -1004 -1013]\n",
      "  [-1012  -998  -996 ... -1004 -1007 -1011]\n",
      "  ...\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[ -988  -999  -990 ...  -995 -1005  -991]\n",
      "  [ -996 -1002  -994 ...  -995 -1006  -998]\n",
      "  [-1004  -999 -1000 ...  -999 -1015 -1012]\n",
      "  ...\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [-1024 -1024 -1024 ... -1024 -1024 -1024]\n",
      "  [    0     0     0 ...     0     0     0]]\n",
      "\n",
      " [[    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  ...\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]\n",
      "  [    0     0     0 ...     0     0     0]]]'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m CTDataModule()\n\u001b[1;32m      2\u001b[0m datamodule\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 137\u001b[0m, in \u001b[0;36mCTDataModule.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataset \u001b[38;5;241m=\u001b[39m CTDataset(val_scans, val_masks, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;241m=\u001b[39m CTDataset(test_scans, test_masks, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms)\n\u001b[0;32m--> 137\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset)\n",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m, in \u001b[0;36mCTDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_file)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m---> 15\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# path_elements = list(Path(image_file).parts)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# index = path_elements.index('images')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# path_elements[index] = 'labels'\u001b[39;00m\n\u001b[1;32m     21\u001b[0m mask_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages_ct_masks[idx]\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "datamodule = CTDataModule()\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
