{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/Documents/RISA/magisterka/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from patchify import patchify\n",
    "\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nibabel.processing import resample_to_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, images_ct_scans, images_ct_masks, transform=None):\n",
    "        self.images_ct_scans = images_ct_scans\n",
    "        self.images_ct_masks = images_ct_masks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_ct_scans)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.images_ct_scans[idx]\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        path_elements = list(Path(image_file).parts)\n",
    "        index = path_elements.index('images')\n",
    "        path_elements[index] = 'labels'\n",
    "\n",
    "        mask_filepath = os.path.join(*path_elements)\n",
    "        mask = cv2.imread(str(mask_filepath))\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "            # mask = self.transform(image=mask)[\"image\"]\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.augmentations = A.Compose([\n",
    "        A.Resize(height=50, width=50),\n",
    "        # A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "        # A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.ToFloat(max_value=255, always_apply=True),\n",
    "        ToTensorV2()\n",
    "        ])\n",
    "        self.transforms = A.Compose([\n",
    "        A.Resize(height=50, width=50),\n",
    "        # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.ToFloat(max_value=255, always_apply=True),\n",
    "        ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "        self.ct_dataset= None\n",
    "\n",
    "        self.all_ct_scan_patches = []\n",
    "        self.all_ct_mask_patches = []\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.ct_dataset = load_dataset(\"andreped/AeroPath\")\n",
    "\n",
    "        print(self.ct_dataset)\n",
    "        for img in range(len(self.ct_dataset['test'])):\n",
    "            # print(img)     #just stop here to see all file names printed\n",
    "                    \n",
    "            large_image = self.ct_dataset['test'][img]\n",
    "\n",
    "            ct_image = nib.load(large_image[\"ct\"])\n",
    "            ct_image = resample_to_output(ct_image, order=1)\n",
    "            ct_data_scan = ct_image.get_fdata().astype(\"int32\")\n",
    "            # print(ct_data_scan.shape)\n",
    "\n",
    "            ct_mask = nib.load(large_image[\"airways\"])\n",
    "            ct_mask = resample_to_output(ct_mask, order=1)\n",
    "            ct_data_mask = ct_mask.get_fdata().astype(\"int32\")\n",
    "                    \n",
    "            percent_size_x = 0.5  # Przykładowo 20% w osi X\n",
    "            percent_size_y = 0.5  # Przykładowo 20% w osi Y\n",
    "            fixed_size_z = 50  # Stała liczba sliców w osi Z\n",
    "\n",
    "            scan_shape = ct_data_scan.shape\n",
    "\n",
    "            patch_size_x = min(int(round(scan_shape[0] * percent_size_x)), scan_shape[0])\n",
    "            patch_size_y = min(int(round(scan_shape[1] * percent_size_y)), scan_shape[1])\n",
    "\n",
    "            patch_size = (patch_size_x, patch_size_y, fixed_size_z)\n",
    "\n",
    "            print(patch_size)\n",
    "\n",
    "            step = patch_size\n",
    "\n",
    "            patches_scan = patchify(ct_data_scan, patch_size, step=step)\n",
    "            patches_mask = patchify(ct_data_mask, patch_size, step=step)\n",
    "\n",
    "            # Pętle do iteracji przez otrzymane fragmenty danego skanu\n",
    "            for i in range(patches_scan.shape[0]):\n",
    "                for j in range(patches_scan.shape[1]):\n",
    "                    for k in range(patches_scan.shape[2]):\n",
    "                        patch_scan = patches_scan[i, j, k, :, :, :]\n",
    "                        patch_mask = patches_mask[i, j, k, :, :, :]\n",
    "                            \n",
    "                        self.all_ct_scan_patches.append(patch_scan)\n",
    "                        self.all_ct_mask_patches.append(patch_mask)\n",
    "\n",
    "##################################################################### for testing purposes\n",
    "            # print(len(all_img_patches))\n",
    "            # fig, ax = plt.subplots(2, 2, figsize=(20, 12))\n",
    "            # ax[0,0].cla()\n",
    "            # ax[0,1].cla()\n",
    "            # ax[1,0].cla()\n",
    "            # ax[1,1].cla()\n",
    "            # ax[0,0].imshow(all_img_patches[0][..., 1], cmap=\"gray\")\n",
    "            # ax[0,1].imshow(all_img_patches[patches.shape[2] + 1][..., 1], cmap=\"gray\")\n",
    "            # ax[1,0].imshow(all_img_patches[2*patches.shape[2] + 1][..., 1], cmap=\"gray\")\n",
    "            # ax[1,1].imshow(all_img_patches[3*patches.shape[2] + 1][..., 1], cmap=\"gray\")\n",
    "\n",
    "            # plt.show()\n",
    "\n",
    "            # break\n",
    "#####################################################################\n",
    "\n",
    "        # images = np.array(all_img_patches)\n",
    "        # images = np.expand_dims(images, -1)\n",
    "                        \n",
    "            if img == 2:\n",
    "                break\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        # Split the data and assign datasets for use in dataloaders\n",
    "\n",
    "        all_indices = np.arange(len(self.all_ct_scan_patches))\n",
    "\n",
    "        train_index, val_index = train_test_split(all_indices, test_size = 0.3, random_state=42)\n",
    "        val_index, test_index = train_test_split(val_index, test_size = 0.5, random_state=42)\n",
    "\n",
    "        # print('Indeksy zbioru walidacyjnego:', val_scans)\n",
    "        # print('Indeksy zbioru testowego:', test_scans)\n",
    "        # print('Indeksy zbioru treningowego:', train_scans)\n",
    "\n",
    "        train_scans = self.all_ct_scan_patches[train_index]\n",
    "        train_masks = self.all_ct_mask_patches[train_index]\n",
    "\n",
    "        val_scans = self.all_ct_scan_patches[val_index]\n",
    "        val_masks = self.all_ct_mask_patches[val_index]\n",
    "\n",
    "        test_scans = self.all_ct_scan_patches[test_index]\n",
    "        test_masks = self.all_ct_mask_patches[test_index]\n",
    "\n",
    "\n",
    "        self.train_dataset = CTDataset(train_scans, train_masks, transform=self.augmentations)\n",
    "        self.val_dataset = CTDataset(val_scans, val_masks, transform=self.transforms)\n",
    "        self.test_dataset = CTDataset(test_scans, test_masks, transform=self.transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=12)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=12)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['ct', 'airways', 'lungs'],\n",
      "        num_rows: 27\n",
      "    })\n",
      "})\n",
      "(194, 194, 50)\n",
      "(190, 190, 50)\n",
      "(190, 190, 50)\n",
      "Indeksy zbioru walidacyjnego: [34 12  4 44 36 25 48  8 37]\n",
      "Indeksy zbioru testowego: [ 0  5 46 52 13 31  6 17  3]\n",
      "Indeksy zbioru treningowego: [41 19 30 49 50 54 15  9 27 26 16 24 33 55 40 11 32 56 43 29 53  1 21  2\n",
      " 45 39 35 23 47 10 22 18 57 20  7 42 14 28 51 38]\n"
     ]
    }
   ],
   "source": [
    "datamodule = CTDataModule()\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
